{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overview:\n",
    "## This script processes a collection of datasets, typically in CSV format, located in the './somervillema' directory.\n",
    "## It employs the MinHash and LSH (Locality-Sensitive Hashing) algorithms to identify similar columns across these datasets.\n",
    "## The goal is to compute two key metrics for each dataset: \n",
    "## 1. Similarity Score - Indicates how similar a dataset is to others based on the columns.\n",
    "## 2. Joinability Score - Measures the potential of a dataset's columns to be joined with columns from other datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede3fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dcba5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minhash(column):\n",
    "    m = MinHash()\n",
    "    for val in column:\n",
    "        m.update(str(val).encode('utf8'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "004143f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_column_counts = {}\n",
    "\n",
    "lsh = MinHashLSH(threshold=0.2, num_perm=128)\n",
    "minhashes={}\n",
    "for filename in os.listdir('./somervillema'):\n",
    "    if filename.endswith('.csv'):\n",
    "        try:\n",
    "            df = pd.read_csv(f'./somervillema/{filename}',header=0,dtype=str)\n",
    "            df = df.dropna(axis=1, how='all')\n",
    "            total_column_counts[filename] = len(df.columns)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "        for column in df.columns:\n",
    "            mh = create_minhash(df[column])\n",
    "            minhashes[(filename,column)] = mh\n",
    "            lsh.insert(f\"{filename}_{column}\",mh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fd1ce1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns similar to ('3ms3-ngki.csv', 'Year'):\n",
      "3qxw-3aiy.csv_mmwr_year\n",
      "6j4n-batb.csv_Year\n",
      "bi8e-5vw8.csv_Year\n",
      "qu9x-4xq5.csv_Year\n"
     ]
    }
   ],
   "source": [
    "query_key = ('3ms3-ngki.csv', 'Year')\n",
    "\n",
    "if query_key in minhashes:\n",
    "    # Query the LSH for similar columns\n",
    "    result = lsh.query(minhashes[query_key])\n",
    "\n",
    "    # Filter out any column from the same dataset as the query_key\n",
    "    filtered_result = [r for r in result if not r.startswith(f\"{query_key[0]}_\")]\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Columns similar to {query_key}:\")\n",
    "    for res in filtered_result:\n",
    "        print(res)\n",
    "else:\n",
    "    print(f\"No MinHash found for {query_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "abf3ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in minhashes:\n",
    "#     print(key,minhashes[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "400a6958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns similar to ('3ms3-ngki.csv', 'Latitude'):\n",
      "6j4n-batb.csv_Latitude\n"
     ]
    }
   ],
   "source": [
    "query_key = ('3ms3-ngki.csv', 'Latitude')\n",
    "# Check if the query key exists in the minhashes dictionary\n",
    "if query_key in minhashes:\n",
    "    # Query the LSH for similar columns\n",
    "    result = lsh.query(minhashes[query_key])\n",
    "\n",
    "    # Filter out the query_key itself from the results\n",
    "    filtered_result = [r for r in result if not r.startswith(f\"{query_key[0]}_\")]\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Columns similar to {query_key}:\")\n",
    "    for res in filtered_result:\n",
    "        print(res)\n",
    "else:\n",
    "    print(f\"No MinHash found for {query_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4ea46bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83fd4c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Scores:\n",
      "3qxw-3aiy.csv: Similarity Score = 6.89\t Joinability Score = 0.33\n",
      "ezmv-8wys.csv: Similarity Score = 47.84\t Joinability Score = 0.89\n",
      "cmth-mghs.csv: Similarity Score = 16.47\t Joinability Score = 0.67\n",
      "qsv6-v7hu.csv: Similarity Score = 29.85\t Joinability Score = 0.65\n",
      "6j4n-batb.csv: Similarity Score = 13.57\t Joinability Score = 1.00\n",
      "4pyi-uqq6.csv: Similarity Score = 12.00\t Joinability Score = 0.20\n",
      "8r94-vs2v.csv: Similarity Score = 1.00\t Joinability Score = 0.33\n",
      "qu9x-4xq5.csv: Similarity Score = 32.14\t Joinability Score = 1.00\n",
      "wz6k-gm5k.csv: Similarity Score = 1.47\t Joinability Score = 0.21\n",
      "vxgw-vmky.csv: Similarity Score = 1.00\t Joinability Score = 0.30\n",
      "9wbi-ck3z.csv: Similarity Score = 3.00\t Joinability Score = 0.43\n",
      "754v-8e35.csv: Similarity Score = 1.40\t Joinability Score = 0.40\n",
      "bi8e-5vw8.csv: Similarity Score = 36.51\t Joinability Score = 0.82\n",
      "xavb-4s9w.csv: Similarity Score = 13.70\t Joinability Score = 0.60\n",
      "62z4-avqc.csv: Similarity Score = 9.14\t Joinability Score = 0.57\n",
      "6x35-pz53.csv: Similarity Score = 17.60\t Joinability Score = 0.60\n",
      "3ms3-ngki.csv: Similarity Score = 13.57\t Joinability Score = 1.00\n"
     ]
    }
   ],
   "source": [
    "# Calculating Similarity and Joinability Score for each tabular dataset in Somerville\n",
    "\n",
    "# Dictionaries for counts\n",
    "similar_column_counts = {}\n",
    "joinable_column_sets = {dataset: set() for dataset in total_column_counts}\n",
    "\n",
    "# Loop through every column in every dataset\n",
    "for key in minhashes:\n",
    "    dataset, column = key\n",
    "    \n",
    "    result = lsh.query(minhashes[key])\n",
    "    filtered_result = [r for r in result if r.split('_')[0] != dataset]\n",
    "\n",
    "    # Update similar column counts and joinable column sets\n",
    "    if filtered_result:\n",
    "        joinable_column_sets[dataset].add(column)\n",
    "    for res in filtered_result:\n",
    "        res_dataset = res.split('_')[0]\n",
    "        similar_column_counts[res_dataset] = similar_column_counts.get(res_dataset, 0) + 1\n",
    "\n",
    "# Calculate and print the similarity and joinability score for each dataset\n",
    "print(\"\\nSimilarity Scores:\")\n",
    "for dataset in total_column_counts:\n",
    "    similar_count = similar_column_counts.get(dataset, 0)\n",
    "    total_count = total_column_counts[dataset]\n",
    "    joinable_count = len(joinable_column_sets[dataset])\n",
    "    similarity_score = similar_count / total_count if total_count > 0 else 0\n",
    "    joinability_score = joinable_count / total_count if total_count > 0 else 0\n",
    "    print(f\"{dataset}: Similarity Score = {similarity_score:.2f}\\t Joinability Score = {joinability_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e37e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
