{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73d49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Joinability Analysis using MinHash and Locality Sensitive Hashing (LSH)\n",
    "\n",
    "This notebook demonstrates the use of MinHash and LSH for identifying joinable columns across multiple datasets. \n",
    "The analysis is performed on a collection of CSV files stored in the './somervillema' directory.\n",
    "\n",
    "Overview of the Process:\n",
    "1. Read each CSV file in the specified directory.\n",
    "2. For each column in these CSV files, create a MinHash signature. \n",
    "3. Insert these MinHash signatures into an LSH index.\n",
    "4. Perform a query using a specific column's MinHash to find similar columns in the collection of datasets.\n",
    "5. Display the results, showing which columns from different datasets are potentially joinable with the query column.\n",
    "\n",
    "Functions:\n",
    "- create_minhash(column): Generates a MinHash signature for a given column from a DataFrame.\n",
    "\n",
    "Key Variables:\n",
    "- lsh: An instance of MinHashLSH, used for indexing MinHash signatures.\n",
    "- minhashes: A dictionary that stores the MinHash signatures of each column.\n",
    "- query_key: A tuple representing the dataset and column name used for querying the LSH index.\n",
    "\n",
    "Query Execution:\n",
    "- The query is executed for the 'Year' column in the '3ms3-ngki.csv' dataset.\n",
    "- The LSH index is queried to find columns similar to this 'Year' column.\n",
    "- Results are filtered to exclude the query column itself and then printed.\n",
    "\n",
    "Note: The script handles EmptyDataError to skip over any CSV files that are empty or unreadable.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ede3fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dcba5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minhash(column):\n",
    "    m = MinHash()\n",
    "    for val in column:\n",
    "        m.update(str(val).encode('utf8'))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "004143f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_column_counts = {}\n",
    "\n",
    "lsh = MinHashLSH(threshold=0.2, num_perm=128)\n",
    "minhashes={}\n",
    "for filename in os.listdir('./somervillema'):\n",
    "    if filename.endswith('.csv'):\n",
    "        try:\n",
    "            df = pd.read_csv(f'./somervillema/{filename}',header=0,dtype=str)\n",
    "            df = df.dropna(axis=1, how='all')\n",
    "            total_column_counts[filename] = len(df.columns)\n",
    "        except pd.errors.EmptyDataError:\n",
    "            continue\n",
    "        for column in df.columns:\n",
    "            mh = create_minhash(df[column])\n",
    "            minhashes[(filename,column)] = mh\n",
    "            lsh.insert(f\"{filename}_{column}\",mh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fd1ce1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns similar to ('3ms3-ngki.csv', 'Year'):\n",
      "3qxw-3aiy.csv_mmwr_year\n",
      "6j4n-batb.csv_Year\n",
      "bi8e-5vw8.csv_Year\n",
      "qu9x-4xq5.csv_Year\n"
     ]
    }
   ],
   "source": [
    "query_key = ('3ms3-ngki.csv', 'Year')\n",
    "\n",
    "if query_key in minhashes:\n",
    "    # Query the LSH for similar columns\n",
    "    result = lsh.query(minhashes[query_key])\n",
    "\n",
    "    # Filter out any column from the same dataset as the query_key\n",
    "    filtered_result = [r for r in result if not r.startswith(f\"{query_key[0]}_\")]\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Columns similar to {query_key}:\")\n",
    "    for res in filtered_result:\n",
    "        print(res)\n",
    "else:\n",
    "    print(f\"No MinHash found for {query_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "abf3ffe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in minhashes:\n",
    "#     print(key,minhashes[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "400a6958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns similar to ('3ms3-ngki.csv', 'Latitude'):\n",
      "6j4n-batb.csv_Latitude\n"
     ]
    }
   ],
   "source": [
    "query_key = ('3ms3-ngki.csv', 'Latitude')\n",
    "# Check if the query key exists in the minhashes dictionary\n",
    "if query_key in minhashes:\n",
    "    # Query the LSH for similar columns\n",
    "    result = lsh.query(minhashes[query_key])\n",
    "\n",
    "    # Filter out the query_key itself from the results\n",
    "    filtered_result = [r for r in result if not r.startswith(f\"{query_key[0]}_\")]\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Columns similar to {query_key}:\")\n",
    "    for res in filtered_result:\n",
    "        print(res)\n",
    "else:\n",
    "    print(f\"No MinHash found for {query_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4ea46bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83fd4c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Scores:\n",
      "3qxw-3aiy.csv: Similarity Score = 6.89\t Joinability Score = 0.33\n",
      "ezmv-8wys.csv: Similarity Score = 47.84\t Joinability Score = 0.89\n",
      "cmth-mghs.csv: Similarity Score = 16.47\t Joinability Score = 0.67\n",
      "qsv6-v7hu.csv: Similarity Score = 29.85\t Joinability Score = 0.65\n",
      "6j4n-batb.csv: Similarity Score = 13.57\t Joinability Score = 1.00\n",
      "4pyi-uqq6.csv: Similarity Score = 12.00\t Joinability Score = 0.20\n",
      "8r94-vs2v.csv: Similarity Score = 1.00\t Joinability Score = 0.33\n",
      "qu9x-4xq5.csv: Similarity Score = 32.14\t Joinability Score = 1.00\n",
      "wz6k-gm5k.csv: Similarity Score = 1.47\t Joinability Score = 0.21\n",
      "vxgw-vmky.csv: Similarity Score = 1.00\t Joinability Score = 0.30\n",
      "9wbi-ck3z.csv: Similarity Score = 3.00\t Joinability Score = 0.43\n",
      "754v-8e35.csv: Similarity Score = 1.40\t Joinability Score = 0.40\n",
      "bi8e-5vw8.csv: Similarity Score = 36.51\t Joinability Score = 0.82\n",
      "xavb-4s9w.csv: Similarity Score = 13.70\t Joinability Score = 0.60\n",
      "62z4-avqc.csv: Similarity Score = 9.14\t Joinability Score = 0.57\n",
      "6x35-pz53.csv: Similarity Score = 17.60\t Joinability Score = 0.60\n",
      "3ms3-ngki.csv: Similarity Score = 13.57\t Joinability Score = 1.00\n"
     ]
    }
   ],
   "source": [
    "# Calculating Similarity and Joinability Score for each tabular dataset in Somerville\n",
    "\n",
    "# Dictionaries for counts\n",
    "similar_column_counts = {}\n",
    "joinable_column_sets = {dataset: set() for dataset in total_column_counts}\n",
    "\n",
    "# Loop through every column in every dataset\n",
    "for key in minhashes:\n",
    "    dataset, column = key\n",
    "    \n",
    "    result = lsh.query(minhashes[key])\n",
    "    filtered_result = [r for r in result if r.split('_')[0] != dataset]\n",
    "\n",
    "    # Update similar column counts and joinable column sets\n",
    "    if filtered_result:\n",
    "        joinable_column_sets[dataset].add(column)\n",
    "    for res in filtered_result:\n",
    "        res_dataset = res.split('_')[0]\n",
    "        similar_column_counts[res_dataset] = similar_column_counts.get(res_dataset, 0) + 1\n",
    "\n",
    "# Calculate and print the similarity and joinability score for each dataset\n",
    "print(\"\\nSimilarity Scores:\")\n",
    "for dataset in total_column_counts:\n",
    "    similar_count = similar_column_counts.get(dataset, 0)\n",
    "    total_count = total_column_counts[dataset]\n",
    "    joinable_count = len(joinable_column_sets[dataset])\n",
    "    similarity_score = similar_count / total_count if total_count > 0 else 0\n",
    "    joinability_score = joinable_count / total_count if total_count > 0 else 0\n",
    "    print(f\"{dataset}: Similarity Score = {similarity_score:.2f}\\t Joinability Score = {joinability_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c1681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
